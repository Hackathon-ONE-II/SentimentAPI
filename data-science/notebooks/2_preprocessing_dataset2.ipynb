{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 2. Pr√©-processamento e Limpeza (Avan√ßado) - Dataset 2\n",
                "\n",
                "Este notebook realiza a limpeza e prepara√ß√£o dos dados para modelagem, incluindo tratamento de emojis, g√≠rias e nega√ß√£o.\n",
                "\n",
                "## Objetivos\n",
                "- Limpeza de texto (preservando pontua√ß√£o relevante).\n",
                "- Tratamento de Emojis (demojize).\n",
                "- Normaliza√ß√£o de G√≠rias.\n",
                "- Marca√ß√£o de Nega√ß√£o.\n",
                "- Tokeniza√ß√£o e remo√ß√£o de stopwords.\n",
                "- Cria√ß√£o do alvo `sentiment` (bin√°rio).\n",
                "- Exporta√ß√£o do dataset processado para `datasets/processed/reviews_dataset2_advanced.csv`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import nltk\n",
                "import re\n",
                "from nltk.corpus import stopwords\n",
                "from nltk.tokenize import word_tokenize\n",
                "import emoji\n",
                "import os\n",
                "\n",
                "# Configura√ß√£o inicial\n",
                "nltk.download('punkt', quiet=True)\n",
                "nltk.download('stopwords', quiet=True)\n",
                "stop_words = set(stopwords.words('portuguese'))\n",
                "# Remover palavras de nega√ß√£o das stopwords para n√£o atrapalhar a marca√ß√£o de nega√ß√£o\n",
                "negation_terms = {'n√£o', 'nao', 'nem', 'nunca', 'jamais', 'nada', 'ningu√©m', 'ninguem'}\n",
                "stop_words = stop_words - negation_terms"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Carregamento dos Dados"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>date</th>\n",
                            "      <th>rating</th>\n",
                            "      <th>content</th>\n",
                            "      <th>product_url</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>01 fev. 2025</td>\n",
                            "      <td>5</td>\n",
                            "      <td>Muito bom gostei.</td>\n",
                            "      <td>https://produto.mercadolivre.com.br/MLB-357687...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>22 jan. 2025</td>\n",
                            "      <td>5</td>\n",
                            "      <td>Perfeito. Eu simplesmente amei , ele e maravil...</td>\n",
                            "      <td>https://produto.mercadolivre.com.br/MLB-357687...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>12 jan. 2025</td>\n",
                            "      <td>5</td>\n",
                            "      <td>Muito cheiroso e a consist√™ncia e maravilhosa.</td>\n",
                            "      <td>https://produto.mercadolivre.com.br/MLB-357687...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>29 nov. 2024</td>\n",
                            "      <td>4</td>\n",
                            "      <td></td>\n",
                            "      <td>https://produto.mercadolivre.com.br/MLB-404730...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>12 fev. 2025</td>\n",
                            "      <td>5</td>\n",
                            "      <td>Produto maravilhoso.</td>\n",
                            "      <td>https://produto.mercadolivre.com.br/MLB-404730...</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "           date  rating                                            content  \\\n",
                            "0  01 fev. 2025       5                                  Muito bom gostei.   \n",
                            "1  22 jan. 2025       5  Perfeito. Eu simplesmente amei , ele e maravil...   \n",
                            "2  12 jan. 2025       5     Muito cheiroso e a consist√™ncia e maravilhosa.   \n",
                            "3  29 nov. 2024       4                                                      \n",
                            "4  12 fev. 2025       5                               Produto maravilhoso.   \n",
                            "\n",
                            "                                         product_url  \n",
                            "0  https://produto.mercadolivre.com.br/MLB-357687...  \n",
                            "1  https://produto.mercadolivre.com.br/MLB-357687...  \n",
                            "2  https://produto.mercadolivre.com.br/MLB-357687...  \n",
                            "3  https://produto.mercadolivre.com.br/MLB-404730...  \n",
                            "4  https://produto.mercadolivre.com.br/MLB-404730...  "
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "file_path = '../datasets/reviews_mercadolivre_com_br_2.json'\n",
                "df = pd.read_json(file_path)\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Dicion√°rio de G√≠rias"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "slang_map = {\n",
                "    'vc': 'voc√™',\n",
                "    'vcs': 'voc√™s',\n",
                "    'tb': 'tamb√©m',\n",
                "    'tbm': 'tamb√©m',\n",
                "    'pq': 'porque',\n",
                "    'q': 'que',\n",
                "    'k': '', 'kk': '', 'kkk': '', 'kkkk': '', 'rs': '',\n",
                "    'mto': 'muito',\n",
                "    'mt': 'muito',\n",
                "    'ta': 'est√°',\n",
                "    'eh': '√©',\n",
                "    'hj': 'hoje',\n",
                "    'td': 'tudo',\n",
                "    'blz': 'beleza',\n",
                "    'flw': 'falou',\n",
                "    'abs': 'abra√ßos',\n",
                "    'tmj': 'tamo junto',\n",
                "    'n': 'n√£o',\n",
                "    's': 'sim',\n",
                "    'obg': 'obrigado',\n",
                "    'top': '√≥timo',\n",
                "    'show': '√≥timo'\n",
                "}\n",
                "\n",
                "def normalize_slang(text, slang_map):\n",
                "    words = text.split()\n",
                "    normalized_words = [slang_map.get(word, word) for word in words]\n",
                "    return \" \".join(normalized_words)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Limpeza e Tratamento Avan√ßado"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>content</th>\n",
                            "      <th>processed_text</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>Muito bom gostei.</td>\n",
                            "      <td>bom gostei</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>Perfeito. Eu simplesmente amei , ele e maravil...</td>\n",
                            "      <td>perfeito simplesmente amei maravilhoso super h...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>Muito cheiroso e a consist√™ncia e maravilhosa.</td>\n",
                            "      <td>cheiroso consist√™ncia maravilhosa</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td></td>\n",
                            "      <td></td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>Produto maravilhoso.</td>\n",
                            "      <td>produto maravilhoso</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>Muito bom. Veio certinho. Agora √© usar pra sab...</td>\n",
                            "      <td>bom veio certinho agora usar pra saber resulta...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6</th>\n",
                            "      <td>Gosto muito.</td>\n",
                            "      <td>gosto</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>7</th>\n",
                            "      <td>Amei!!! para meu cabelo foi √≥timo.</td>\n",
                            "      <td>amei ! ! ! cabelo √≥timo</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>8</th>\n",
                            "      <td>Muito bom bem consistente custo benef√≠cio √≥timo.</td>\n",
                            "      <td>bom bem consistente custo benef√≠cio √≥timo</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9</th>\n",
                            "      <td>Hidrata muito,amei.</td>\n",
                            "      <td>hidrata muitoamei</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                             content  \\\n",
                            "0                                  Muito bom gostei.   \n",
                            "1  Perfeito. Eu simplesmente amei , ele e maravil...   \n",
                            "2     Muito cheiroso e a consist√™ncia e maravilhosa.   \n",
                            "3                                                      \n",
                            "4                               Produto maravilhoso.   \n",
                            "5  Muito bom. Veio certinho. Agora √© usar pra sab...   \n",
                            "6                                       Gosto muito.   \n",
                            "7                 Amei!!! para meu cabelo foi √≥timo.   \n",
                            "8   Muito bom bem consistente custo benef√≠cio √≥timo.   \n",
                            "9                                Hidrata muito,amei.   \n",
                            "\n",
                            "                                      processed_text  \n",
                            "0                                         bom gostei  \n",
                            "1  perfeito simplesmente amei maravilhoso super h...  \n",
                            "2                  cheiroso consist√™ncia maravilhosa  \n",
                            "3                                                     \n",
                            "4                                produto maravilhoso  \n",
                            "5  bom veio certinho agora usar pra saber resulta...  \n",
                            "6                                              gosto  \n",
                            "7                            amei ! ! ! cabelo √≥timo  \n",
                            "8          bom bem consistente custo benef√≠cio √≥timo  \n",
                            "9                                  hidrata muitoamei  "
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "def clean_text_advanced(text):\n",
                "    if not isinstance(text, str):\n",
                "        return \"\"\n",
                "    \n",
                "    # Tratar Emojis (Demojize): üëç -> :thumbs_up:\n",
                "    # Usamos language='pt' se dispon√≠vel na vers√£o, sen√£o padr√£o en\n",
                "    text = emoji.demojize(text, language='pt') \n",
                "    \n",
                "    # Converter para min√∫sculas\n",
                "    text = text.lower()\n",
                "    \n",
                "    # Substituir hifens por espa√ßo\n",
                "    text = text.replace('-', ' ')\n",
                "    \n",
                "    # Normalizar G√≠rias\n",
                "    text = normalize_slang(text, slang_map)\n",
                "    \n",
                "    # Remover caracteres especiais MAS manter pontua√ß√£o relevante (! ?)\n",
                "    # Regex: Mant√©m letras, n√∫meros, espa√ßos, acentos, !, ?, :, _ (para emojis)\n",
                "    text = re.sub(r'[^a-zA-Z0-9\\u00C0-\\u00FF\\s!\\?:_]', '', text)\n",
                "    \n",
                "    # Espa√ßar pontua√ß√£o para ser tokenizada separadamente \"Bom!\" -> \"Bom !\"\n",
                "    text = re.sub(r'([!\\?])', r' \\1 ', text)\n",
                "    \n",
                "    # Remover espa√ßos extras\n",
                "    text = re.sub(r'\\s+', ' ', text).strip()\n",
                "    \n",
                "    return text\n",
                "\n",
                "def mark_negation_func(text_tokens):\n",
                "    \"\"\"\n",
                "    Marca nega√ß√£o em tokens at√© a pr√≥xima pontua√ß√£o.\n",
                "    Ex: ['n√£o', 'gostei', 'do', 'produto', '.'] -> ['n√£o', 'gostei_NEG', 'do_NEG', 'produto_NEG', '.']\n",
                "    \"\"\"\n",
                "    negations = negation_terms\n",
                "    punctuation = {'!', '?', '.', ',', ':', ';', '...'}\n",
                "    \n",
                "    result = []\n",
                "    neg_state = False\n",
                "    \n",
                "    for word in text_tokens:\n",
                "        # Se for pontua√ß√£o, reseta nega√ß√£o\n",
                "        if word in punctuation:\n",
                "            neg_state = False\n",
                "            result.append(word)\n",
                "            continue\n",
                "            \n",
                "        # Se palavra atual √© termo de nega√ß√£o, ativa estado (e mant√©m a palavra original)\n",
                "        if word in negations:\n",
                "            neg_state = True\n",
                "            result.append(word)\n",
                "            continue\n",
                "            \n",
                "        # Se estado ativo, adiciona sufixo _NEG\n",
                "        if neg_state:\n",
                "            result.append(word + '_NEG')\n",
                "        else:\n",
                "            result.append(word)\n",
                "            \n",
                "    return result\n",
                "\n",
                "def process_text_pipeline(text):\n",
                "    # Limpeza b√°sica\n",
                "    cleaned = clean_text_advanced(text)\n",
                "    \n",
                "    # Tokeniza√ß√£o\n",
                "    tokens = word_tokenize(cleaned, language='portuguese')\n",
                "    \n",
                "    # Remover stopwords (lembrando que tiramos as de nega√ß√£o da lista)\n",
                "    tokens = [t for t in tokens if t not in stop_words]\n",
                "    \n",
                "    # Marca√ß√£o de Nega√ß√£o\n",
                "    tokens = mark_negation_func(tokens)\n",
                "    \n",
                "    # Filtrar tokens muito curtos (opcional, cuidado com emojis :a:)\n",
                "    # Vamos manter tokens > 1 ou emojis\n",
                "    final_tokens = [t for t in tokens if len(t) > 1 or t in ['!', '?']]\n",
                "    \n",
                "    return \" \".join(final_tokens)\n",
                "\n",
                "# Aplica√ß√£o\n",
                "df['processed_text'] = df['content'].apply(process_text_pipeline)\n",
                "df[['content', 'processed_text']].head(10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Cria√ß√£o do Target e Exporta√ß√£o"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Dados avan√ßados salvos em: ../datasets/processed/reviews_dataset2_advanced.csv\n"
                    ]
                }
            ],
            "source": [
                "df['sentiment'] = df['rating'].apply(lambda x: 1 if x >= 4 else 0)\n",
                "df = df.rename(columns={'content': 'review_text'})\n",
                "\n",
                "# Salvar com novo nome para manter vers√£o anterior\n",
                "output_dir = '../datasets/processed'\n",
                "output_file = os.path.join(output_dir, 'reviews_dataset2_advanced.csv')\n",
                "os.makedirs(output_dir, exist_ok=True)\n",
                "\n",
                "df[['review_text', 'rating', 'sentiment', 'processed_text']].to_csv(output_file, index=False)\n",
                "\n",
                "print(f\"Dados avan√ßados salvos em: {output_file}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
