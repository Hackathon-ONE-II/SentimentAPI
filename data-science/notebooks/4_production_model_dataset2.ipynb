{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 4. Modelo de Produção - Dataset 2\n",
                "\n",
                "Este notebook documenta o desenvolvimento do modelo de Análise de Sentimento da API.\n",
                "O objetivo é sair de uma solução simples (Baseline) e refinar o modelo tratando problemas reais como o desbalanceamento de classes, até chegar na melhor solução para produção.\n",
                "\n",
                "## Roteiro de Experimentos\n",
                "- **Experimento 1 (Baseline)**: Modelo simples sem tratamento de desbalanceamento.\n",
                "- **Experimento 2 (Desbalanceamento)**: Comparação entre Class Weights e SMOTE.\n",
                "- **Experimento 3 (Fine Tuning)**: Otimização de hiperparâmetros com GridSearchCV.\n",
                "- **Final**: Seleção e exportação do modelo vencedor."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.svm import LinearSVC\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
                "import joblib\n",
                "import os\n",
                "from imblearn.over_sampling import SMOTE\n",
                "\n",
                "sns.set_style(\"whitegrid\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Carregamento e Preparação dos Dados"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Carregar dataset pré-processado\n",
                "file_path = '../datasets/processed/reviews_dataset2_advanced.csv'\n",
                "df = pd.read_csv(file_path)\n",
                "df = df.dropna(subset=['processed_text'])\n",
                "\n",
                "X = df['processed_text']\n",
                "y = df['sentiment']\n",
                "\n",
                "# Divisão Estratificada\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, test_size=0.2, random_state=42, stratify=y\n",
                ")\n",
                "\n",
                "print(f\"Treino: {X_train.shape[0]} amostras | Teste: {X_test.shape[0]} amostras\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Verificando Desbalanceamento"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dist = y_train.value_counts(normalize=True) * 100\n",
                "print(\"Distribuição das Classes no Treino:\")\n",
                "print(dist)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Baseline (Sem Tratamento)\n",
                "Vamos treinar um modelo simples de Regressão Logística ignorando o desbalanceamento. Isso serve como linha de base para sabermos se nossas otimizações futuras realmente ajudam."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Vetorização simples para o baseline\n",
                "vec_base = TfidfVectorizer(max_features=5000)\n",
                "X_train_base = vec_base.fit_transform(X_train)\n",
                "X_test_base = vec_base.transform(X_test)\n",
                "\n",
                "# Modelo Padrão\n",
                "model_base = LogisticRegression(random_state=1337, max_iter=1000)\n",
                "model_base.fit(X_train_base, y_train)\n",
                "\n",
                "y_pred_base = model_base.predict(X_test_base)\n",
                "\n",
                "print(\"--- Resultado Baseline ---\")\n",
                "print(classification_report(y_test, y_pred_base))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Análise (Baseline):**\n",
                "Observe o **Recall** da classe minoritária (0). O valor está baixo, o que significa que o modelo está apenas \"chutando\" a classe majoritária para maximizar a Acurácia, ignorando as críticas negativas."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Tratando o Desbalanceamento\n",
                "Testaremos duas técnicas populares para resolver o problema identificado no baseline:\n",
                "\n",
                "1.  **Class Weights**: Penalizar o modelo mais fortemente quando ele erra a classe minoritária.\n",
                "2.  **SMOTE**: Gerar exemplos sintéticos da classe minoritária para equilibrar o treino."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Abordagem A: Class Weights ---\n",
                "print(\"Treinando com Class Weights...\")\n",
                "model_weighted = LogisticRegression(class_weight='balanced', random_state=1337, max_iter=1000)\n",
                "model_weighted.fit(X_train_base, y_train)\n",
                "y_pred_weighted = model_weighted.predict(X_test_base)\n",
                "\n",
                "# --- Abordagem B: SMOTE ---\n",
                "print(\"Aplicando SMOTE...\")\n",
                "smote = SMOTE(random_state=1337)\n",
                "X_train_res, y_train_res = smote.fit_resample(X_train_base, y_train)\n",
                "\n",
                "print(f\"Novo shape de treino (SMOTE): {X_train_res.shape}\")\n",
                "\n",
                "model_smote = LogisticRegression(random_state=1337, max_iter=1000)\n",
                "model_smote.fit(X_train_res, y_train_res)\n",
                "y_pred_smote = model_smote.predict(X_test_base)\n",
                "\n",
                "# Comparação\n",
                "print(\"\\n--- Class Weights Balanced ---\")\n",
                "print(classification_report(y_test, y_pred_weighted))\n",
                "\n",
                "print(\"\\n--- SMOTE ---\")\n",
                "print(classification_report(y_test, y_pred_smote))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Decisão:**\n",
                "Geralmente, em NLP com alta dimensionalidade (TF-IDF), o **Class Weight** tende a funcionar tão bem quanto o SMOTE, com a vantagem de ser computacionalmente mais leve e não introduzir ruído sintético. Vamos seguir otimizando a versão com *Class Weights*."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Fine Tuning (GridSearch)\n",
                "Agora que decidimos usar `class_weight='balanced'`, vamos encontrar o melhor algoritmo e parâmetros.\n",
                "1.  **Logistic Regression** (Probabilístico)\n",
                "2.  **Linear SVC** (Margem máxima, geralmente ótimo para texto)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Pipelines com Class Weight Balanced\n",
                "pipe_lr = Pipeline([\n",
                "    ('tfidf', TfidfVectorizer()),\n",
                "    ('clf', LogisticRegression(class_weight='balanced', max_iter=1000, random_state=1337))\n",
                "])\n",
                "\n",
                "pipe_svc = Pipeline([\n",
                "    ('tfidf', TfidfVectorizer()),\n",
                "    ('clf', LinearSVC(class_weight='balanced', random_state=1337))\n",
                "])\n",
                "\n",
                "pipe_lr_final = Pipeline([\n",
                "    ('tfidf', TfidfVectorizer(ngram_range=(1, 2), sublinear_tf=False)), # Fixamos o que já venceu\n",
                "    ('clf', LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42, solver='liblinear'))\n",
                "])\n",
                "\n",
                "# GRID DE PARÂMETROS\n",
                "\n",
                "# Resultados de GridSearch anteriores:\n",
                "#{'clf__C': 10, 'tfidf__max_features': 10000, 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 2), 'tfidf__sublinear_tf': False}\n",
                "#{'clf__C': 10, 'tfidf__max_features': 15000, 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 2), 'tfidf__sublinear_tf': False}\n",
                "#{'clf__C': 10, 'clf__penalty': 'l2', 'tfidf__max_features': 15000, 'tfidf__min_df': 5}\n",
                "\n",
                "#param_grid = {\n",
                "#    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
                "#    'tfidf__max_features': [5000, 10000],\n",
                "#    'tfidf__min_df': [2, 5],            # Palavra deve aparecer em pelo menos 2 ou 5 docs\n",
                "#    'tfidf__sublinear_tf': [True, False], # Escala logarítmica para frequências\n",
                "#    'clf__C': [0.1, 1, 10]\n",
                "#}\n",
                "\n",
                "# Expandindo os parâmetros em torno dos valores que o GridSearch retornou como melhores.\n",
                "param_grid = {\n",
                "    'tfidf__ngram_range': [(1, 2)], # Já sabemos que (1,2) é melhor que (1,1)\n",
                "    'tfidf__max_features': [10000, 15000], \n",
                "    'tfidf__min_df': [5, 10],       # Testando se limpar mais ajuda a generalizar\n",
                "    'tfidf__sublinear_tf': [False], \n",
                "    'clf__C': [10, 20, 50, 100]    # Expandindo o C para ver até onde vai\n",
                "}\n",
                "\n",
                "# Grade para comparar as penalidades\n",
                "param_grid_l1_l2 = {\n",
                "    'tfidf__max_features': [15000, 20000], # Testando se 20k ajuda ainda mais\n",
                "    'tfidf__min_df': [5],\n",
                "    'clf__C': [5, 10, 15],                 # Testando valores próximos ao 10\n",
                "    'clf__penalty': ['l1', 'l2']           # L1 vs L2\n",
                "}\n",
                "\n",
                "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1337)\n",
                "\n",
                "print(\"Rodando GridSearch para Logistic Regression...\")\n",
                "grid_lr = GridSearchCV(pipe_lr_final, param_grid_l1_l2, cv=cv, scoring='f1', n_jobs=-1)\n",
                "grid_lr.fit(X_train, y_train)\n",
                "print(f\"Melhor F1 (LR): {grid_lr.best_score_:.4f}\")\n",
                "print(f\"Melhores Parâmetros (LR): {grid_lr.best_params_}\")\n",
                "\n",
                "# Como o LR consistentemente retorna resultados melhores, deixaremos o SVC de lado.\n",
                "# print(\"\\nRodando GridSearch para Linear SVC...\")\n",
                "# grid_svc = GridSearchCV(pipe_svc, param_grid, cv=cv, scoring='f1', n_jobs=-1)\n",
                "# grid_svc.fit(X_train, y_train)\n",
                "# print(f\"Melhor F1 (SVC): {grid_svc.best_score_:.4f}\")\n",
                "# print(f\"Melhores Parâmetros (SVC): {grid_svc.best_params_}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Resultado Final\n",
                "Selecionamos o modelo vencedor e avaliamos no conjunto de teste."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Instancia o modelo com os parâmetros finais\n",
                "final_pipeline = Pipeline([\n",
                "    ('tfidf', TfidfVectorizer(\n",
                "        ngram_range=(1, 2), \n",
                "        max_features=15000, \n",
                "        min_df=5, \n",
                "        sublinear_tf=False\n",
                "    )),\n",
                "    ('clf', LogisticRegression(\n",
                "        C=10, \n",
                "        penalty='l2', \n",
                "        solver='liblinear', # Garantindo compatibilidade\n",
                "        class_weight='balanced', \n",
                "        random_state=1337\n",
                "    ))\n",
                "])\n",
                "\n",
                "# Treino\n",
                "final_pipeline.fit(X_train, y_train)\n",
                "\n",
                "# Avaliação no conjunto de teste\n",
                "y_pred = final_pipeline.predict(X_test)\n",
                "\n",
                "print(\"--- RELATÓRIO DE DESEMPENHO FINAL ---\")\n",
                "print(classification_report(y_test, y_pred))\n",
                "\n",
                "# Matriz de Confusão para análise de erros\n",
                "cm = confusion_matrix(y_test, y_pred)\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens')\n",
                "plt.xlabel('Predito')\n",
                "plt.ylabel('Real')\n",
                "plt.title('Matriz de Confusão Final')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Salvar Modelo de Produção"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_path = '../models/production_model.pkl'\n",
                "joblib.dump(final_pipeline, model_path)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "ds",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
