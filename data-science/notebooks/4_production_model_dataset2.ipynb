{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 4. Modelo de Produção - Dataset 2\n",
                "\n",
                "Este notebook documenta o desenvolvimento do modelo de Análise de Sentimento da API.\n",
                "O objetivo é sair de uma solução simples (Baseline) e refinar o modelo tratando problemas reais como o desbalanceamento de classes, até chegar na melhor solução para produção.\n",
                "\n",
                "## Roteiro de Experimentos\n",
                "- **Experimento 1 (Baseline)**: Modelo simples sem tratamento de desbalanceamento.\n",
                "- **Experimento 2 (Desbalanceamento)**: Comparação entre Class Weights e SMOTE.\n",
                "- **Experimento 3 (Fine Tuning)**: Otimização de hiperparâmetros com GridSearchCV.\n",
                "- **Final**: Seleção e exportação do modelo vencedor."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.svm import LinearSVC\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
                "import joblib\n",
                "import os\n",
                "from imblearn.over_sampling import SMOTE\n",
                "\n",
                "sns.set_style(\"whitegrid\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Carregamento e Preparação dos Dados"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Carregar dataset pré-processado\n",
                "file_path = '../datasets/processed/reviews_dataset2_advanced.csv'\n",
                "df = pd.read_csv(file_path)\n",
                "df = df.dropna(subset=['processed_text'])\n",
                "\n",
                "X = df['processed_text']\n",
                "y = df['sentiment']\n",
                "\n",
                "# Divisão Estratificada\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, test_size=0.2, random_state=42, stratify=y\n",
                ")\n",
                "\n",
                "print(f\"Treino: {X_train.shape[0]} amostras | Teste: {X_test.shape[0]} amostras\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Verificando Desbalanceamento"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dist = y_train.value_counts(normalize=True) * 100\n",
                "print(\"Distribuição das Classes no Treino:\")\n",
                "print(dist)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Baseline (Sem Tratamento)\n",
                "Vamos treinar um modelo simples de Regressão Logística ignorando o desbalanceamento. Isso serve como linha de base para sabermos se nossas otimizações futuras realmente ajudam."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Vetorização simples para o baseline\n",
                "vec_base = TfidfVectorizer(max_features=5000)\n",
                "X_train_base = vec_base.fit_transform(X_train)\n",
                "X_test_base = vec_base.transform(X_test)\n",
                "\n",
                "# Modelo Padrão\n",
                "model_base = LogisticRegression(random_state=42, max_iter=1000)\n",
                "model_base.fit(X_train_base, y_train)\n",
                "\n",
                "y_pred_base = model_base.predict(X_test_base)\n",
                "\n",
                "print(\"--- Resultado Baseline ---\")\n",
                "print(classification_report(y_test, y_pred_base))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Análise (Baseline):**\n",
                "Observe o **Recall** da classe minoritária (0). O valor está baixo, o que significa que o modelo está apenas \"chutando\" a classe majoritária para maximizar a Acurácia, ignorando as críticas negativas."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Tratando o Desbalanceamento\n",
                "Testaremos duas técnicas populares para resolver o problema identificado no baseline:\n",
                "\n",
                "1.  **Class Weights**: Penalizar o modelo mais fortemente quando ele erra a classe minoritária.\n",
                "2.  **SMOTE**: Gerar exemplos sintéticos da classe minoritária para equilibrar o treino."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Abordagem A: Class Weights ---\n",
                "print(\"Treinando com Class Weights...\")\n",
                "model_weighted = LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000)\n",
                "model_weighted.fit(X_train_base, y_train)\n",
                "y_pred_weighted = model_weighted.predict(X_test_base)\n",
                "\n",
                "# --- Abordagem B: SMOTE ---\n",
                "print(\"Aplicando SMOTE...\")\n",
                "smote = SMOTE(random_state=42)\n",
                "X_train_res, y_train_res = smote.fit_resample(X_train_base, y_train)\n",
                "\n",
                "print(f\"Novo shape de treino (SMOTE): {X_train_res.shape}\")\n",
                "\n",
                "model_smote = LogisticRegression(random_state=42, max_iter=1000)\n",
                "model_smote.fit(X_train_res, y_train_res)\n",
                "y_pred_smote = model_smote.predict(X_test_base)\n",
                "\n",
                "# Comparação\n",
                "print(\"\\n--- Class Weights Balanced ---\")\n",
                "print(classification_report(y_test, y_pred_weighted))\n",
                "\n",
                "print(\"\\n--- SMOTE ---\")\n",
                "print(classification_report(y_test, y_pred_smote))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Decisão:**\n",
                "Geralmente, em NLP com alta dimensionalidade (TF-IDF), o **Class Weight** tende a funcionar tão bem quanto o SMOTE, com a vantagem de ser computacionalmente mais leve e não introduzir ruído sintético. Vamos seguir otimizando a versão com *Class Weights*."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Experimento 3: Fine Tuning (GridSearch)\n",
                "Agora que decidimos usar `class_weight='balanced'`, vamos encontrar o melhor algoritmo e parâmetros.\n",
                "1.  **Logistic Regression** (Probabilístico)\n",
                "2.  **Linear SVC** (Margem máxima, geralmente ótimo para texto)\n",
                "\n",
                "Parâmetros a testar:\n",
                "-   N-Grams (Unigramas vs Bigramas)\n",
                "-   Tamanho do Vocabulário (5k vs 10k)\n",
                "-   Regularização C"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Pipelines com Class Weight Balanced\n",
                "pipe_lr = Pipeline([\n",
                "    ('tfidf', TfidfVectorizer()),\n",
                "    ('clf', LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42))\n",
                "])\n",
                "\n",
                "pipe_svc = Pipeline([\n",
                "    ('tfidf', TfidfVectorizer()),\n",
                "    ('clf', LinearSVC(class_weight='balanced', random_state=42))\n",
                "])\n",
                "\n",
                "# Grid de Parâmetros\n",
                "param_grid = {\n",
                "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
                "    'tfidf__max_features': [5000, 10000],\n",
                "    'clf__C': [0.1, 1, 10]\n",
                "}\n",
                "\n",
                "print(\"Rodando GridSearch para Logistic Regression...\")\n",
                "grid_lr = GridSearchCV(pipe_lr, param_grid, cv=3, scoring='f1', n_jobs=-1)\n",
                "grid_lr.fit(X_train, y_train)\n",
                "print(f\"Melhor F1 (LR): {grid_lr.best_score_:.4f}\")\n",
                "\n",
                "print(\"\\nRodando GridSearch para Linear SVC...\")\n",
                "grid_svc = GridSearchCV(pipe_svc, param_grid, cv=3, scoring='f1', n_jobs=-1)\n",
                "grid_svc.fit(X_train, y_train)\n",
                "print(f\"Melhor F1 (SVC): {grid_svc.best_score_:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Resultado Final\n",
                "Selecionamos o modelo vencedor e avaliamos no conjunto de teste."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "best_model = grid_lr.best_estimator_ if grid_lr.best_score_ > grid_svc.best_score_ else grid_svc.best_estimator_\n",
                "model_name = \"Logistic Regression\" if grid_lr.best_score_ > grid_svc.best_score_ else \"Linear SVC\"\n",
                "\n",
                "print(f\"VENCEDOR: {model_name}\")\n",
                "print(f\"Melhores Parâmetros: {grid_lr.best_params_ if model_name == 'Logistic Regression' else grid_svc.best_params_}\")\n",
                "\n",
                "# Avaliação Final\n",
                "y_pred_final = best_model.predict(X_test)\n",
                "\n",
                "print(f\"\\n--- Relatório Final ({model_name}) ---\")\n",
                "print(classification_report(y_test, y_pred_final))\n",
                "\n",
                "# Matriz de Confusão\n",
                "cm = confusion_matrix(y_test, y_pred_final)\n",
                "plt.figure(figsize=(6, 5))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
                "plt.title(f'Matriz de Confusão - {model_name}')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Salvar Modelo de Produção"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "production_model_path = '../models/production_model.pkl'\n",
                "joblib.dump(best_model, production_model_path)\n",
                "print(f\"Modelo salvo com sucesso em: {production_model_path}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "data-sci",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
